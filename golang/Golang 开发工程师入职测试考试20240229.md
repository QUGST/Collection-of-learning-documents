# Golang 开发工程师入职测试考试

## 一、基础知识(每题3分，合计24分)

### 1、在 Golang中，interface{}的作用是什么?

在 Golang 中，interface 是一种抽象类型，相对于抽象类型的是具体类型（concrete type）：int，string。interface 是一组 method 的集合，是 duck-type programming 的一种体现。不关心属性（数据），只关心行为（方法）。具体使用中你可以自定义自己的 struct，并提供特定的 interface 里面的 method 就可以把它当成 interface 来使用。实现了“泛型编程”

### 2、解释 Golang 的垃圾回收机制。

#### 垃圾的产生

程序在内存上被分为堆区、栈区、全局数据区、代码段、数据区五个部分。对于C++等早期编程语言栈上的内存由编译器管理回收，堆上的内存空间需要编程人员负责申请与释放。在Go中栈上内存仍由编译器负责管理回收，而堆上的内存由编译器和垃圾收集器负责管理回收，给编程人员带来了极大的便利性。

垃圾是指程序向堆栈申请的内存空间，随着程序的运行已经不再使用这些内存空间，这时如果不释放他们就会造成垃圾也就是内存泄漏。

Golang在GC的演进过程中也经历了很多次变革，大概分为「3个阶段」

#### Go V1.3之前的标记-清除法(mark and sweep)

标记清除法主要有三个步骤

```
暂停STW(stop the world)
标记(Mark phase)
清除(Sweep phase)
停止暂停
```

「暂停」整个程序业务逻辑，区分出「可达对象」和不可达对象，然后做上标记

![截图](cfc2f8b3f798a41ee59af114658690c3.png)

可达对象主要是指程序和对象有可达关系的对象。以上图为例，可达对象为  「对象1->对象2->对象3」、「对象4->对象7」五个对象。
不可达对象为 对象5、对象6

标记完成之后，对未标记的对象进行清除

程序停止暂停，继续跑起来。然后一直循环重复这个过程，一直到整个程序生命周期结束

标记清除法的缺点
整个标记清除法其实非常简单，过程也很明了，但是也有很严重的问题

首先他的第一步就是STW(stop the world),程序暂停之后会出现卡顿的，这个影响非常严重
标记可达对象和非可达对象的时候需要扫描整个heap，复杂度也比较高
在清除非可达对象的时候会产生很多heap碎片

上面最严重的问题其实是STW，Go V1.3 专门针对这个问题做了一期的优化

![截图](990eacd3b76878468f54c06a7528bda0.png)

Go V1.3 做了简单的优化,将STW的步骤提前, 减少STW暂停的时间范围(如下图所示)，因为在清除非可达对象的时候，是不需要程序停止的。

![截图](6051a3200d44d8aa7b2e2bd2f5160ace.png)

#### Go V1.5的三色并发标记法

所谓三色标记法其实就是用三种不同的颜色(灰白黑)来标记各个对象的状态，最后统一回收白色对象，保留黑色对象（灰色对象为过渡态）的方式。让我们来看一看具体过程。

每次新建的对象，默认全部都是白色

![截图](269b6a1fe5ee80db0a9ef7c8b436584e.png)

GC开始回收，则从根节点开始遍历对象，把遍历到的对象全部标记为灰色

注意这里所说的遍历，只遍历根节点下面一个层级的对象(也就是对象1和对象4)，把他们标记为灰色
右边对应的把对象1和对象4从白色标记表的集合中放到了灰色的标记表集合中
把上一步的所有灰色标记表集合中的对象（对象1、对象4）全部遍历一遍，把「遍历到的可达对象标记为灰色」，同时把「灰色对象本身(对象1、对象4)，标记为黑色」

一直重复上一步，直到灰色标记表中无任何对象为止、

回收所有被标记为白色的对象，也就是进行垃圾回收

**三色标记法存在的问题**
我们从三色标记法的过程不难看出，里面会有很多并发流程均会被扫描，执行并发流程的内存可能存在相互依赖。所以为了保证GC过程中的数据安全性，三色标记法在开始之前同样会加上「STW」(stop the world),在扫描确定所有黑白对象之后才会停止「STW」。这样的效率和性能同样是比较低的，同时会引起程序卡顿。

如果不启动STW会发生什么
我们回到上面的例子，假设我们已经执行完了初始一次的扫描，标记了部分对象颜色，此时对象2是指向对象3的，也就是说正常情况下下一次扫描执行之后应该是对象2被标记为黑色，对象3被标记为灰色。

![截图](0e90280b7db76f64890621456f7e3137.png)

因为整个过程是没有启动STW的，所以任何情况都是有可能发生的。所以如果标记扫描还没有扫描到2的时候，「对象4突然指向了对象3」，「同时对象2对对象3的指向断开」(不要习惯性的觉得不会这么巧，程序在跑着的时候任何情况都是会发生的)，然后我们按照三色标记法的计算逻辑执行下去，将所有灰色对象标记为黑色，那么2和7就会被被标记为黑色，然后白色对象会被全部清除，剩下黑色对象。明显这样的GC处理是不合理的，因为对象3是不应该被清除的。

而为了避免这种情况的出现需要破坏这种现象形成的两个前提条件：

条件1: 一个白色对象被黑色对象引用(白色被挂在黑色下)
条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏(灰色同时丢了该白色)

GC在进行垃圾回收的时候，满足下面两种情况之一时，即可保对象不丢失。这两种方式就是「强三色不变式」和「弱三色不变式」。

**强三色不变式**
不允许黑色对象直接指向白色对象，这样就不会有白色对象被误删的情况

![截图](efd7a680b7a914b008914c32c4923cf2.png)

**插入屏障**
方式：在A对象引用(指向)B对象的时候，B对象被强制标记为灰色。

依据:「强三色不变式」

内存槽有两种位置, 「栈」和「堆」. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,「在栈空间的对象操作中不使用. 而仅仅使用在堆空间对象的操作中」. 为了更好的理解，我们来看这样的一个过程

程序根节点是分为栈空间和堆空间的，只有堆空间的对象启用插入屏障机制
因为并发等各种原因，此时对象4需要指向对象8，对象1需要指向对象9

因为对象4在堆空间，启用了插入屏障，所以对象8被标记为灰色
因为对象1在栈空间，未启用插入屏障，所以对象9依然为白色。
上述流程三色标记循环完之后状态如下

![截图](d09a8e0872bef6bf05cc5a247f043bdd.png)

一般情况下现在就应该回收白色元素了。但是我们直接肉眼观察是有问题的，因为对象9其实是不应该被回收的，但是栈空间的元素又没有启动插入屏障机制，所以为了解决这个问题，于是对栈空间的元素在准备回收之前，「重新进行了一次三色标记扫描」，为了扫描数据不被丢失，在「**重新扫描之前还启动了一次STW的保护**」，直到栈空间的元素三色扫描结束

开始重新扫描栈空间的元素

最后直接全部清除白色元素即可。虽然这个流程也启动了STW，但是只是对栈空间的启动，相对之前的全局启动STW性能要提高很多倍。

**弱三色不变式**
所有被黑色对象引用的白色对象都处于灰色保护状态。弱三色不变式强调，黑色对象可以引用白色对象，但是白色对象上游必须有灰色对象来保证其安全被扫描到

![截图](d63cc75ea858f9d55e9c58d0d38d7b26.png)

<br/>

**删除屏障**
方式：被删除的对象，如果自身为灰色或者白色，则被强制标记为灰色

依据：弱三色不变式

在三色标记的过程中，对象1还未来得及把对象5标记为灰色的时候就已经断开了链接。可想而知，这么执行下去的话对象5以及对象2对象3后面都会被清除。但是如果触发了删除写屏障，那么对象5会被标记为灰色。这样后面循环下去，对象5,2,3都会逐一被标记为黑色。从而正确的被保护![截图](b9d54ce362ad7254026925f712c7b18f.png)

这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。

#### Go V1.8混合写屏障机制

从上面的流程可以看出插入写屏障和删除写屏障都是有短板的。
插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活；
删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。
Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。

**混合写屏障规则**
GC开始将栈上的可达对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，
GC期间，任何在栈上创建的新对象，均为黑色。
被删除的对象标记为灰色。
被添加的对象标记为灰色。

总结
GoV1.3- 普通标记清除法，整体过程需要启动STW，效率极低。

GoV1.5- 三色标记法， 堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通

GoV1.8-三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。

```
1.清理终止阶段
暂停程序，所有的处理器在这时会进入安全点(safe point)；
如果当前垃圾收集循环是强制触发的，我们还需要处理还未清理的内存管理单元；
2.标记阶段
将状态切换至_GCmark、开启写屏障、用户程序协助(Mutator Assists)并将根对象入队；
恢复执行程序，标记进程和用于协助的用户程序会开始并发标记内存中的对象，写屏障会将被覆盖的指针和新指针都标记成灰色，而所有新创建的对象都会被直接标记成黑色；
开始扫描根对象，包括所有Goroutine的栈、全局对象以及不在堆中的运行时数据结构，扫描Goroutine栈期间会暂停当前处理器；
依次处理灰色队列中的对象，将对象标记成黑色并将它们指向的对象标记成灰色；
使用分布式的终止算法检查剩余的工作，发现标记阶段完成后进入标记终止阶段；
3.标记终止阶段
暂停程序、将状态切换至_GCmarktermination 并关闭辅助标记的用户程序；
清理处理器上的线程缓存；
4.清理阶段
将状态切换至_GCoff 开始清理阶段、初始化清理状态并关闭写屏障；
恢复用户程序，所有新创建的对象会标记成白色；
后台并发清理所有的内存管理单元，当Goroutine申请新的内存管理单元时就会触发清理；
```

GC触发时机
当满足触发垃圾收集的基本条件：允许垃圾收集、程序没有崩溃并且没有处于垃圾循环；

触发时机

```
1.超过内存大小阙值，分配内存时，当前已分配内存与上一次GC结束时存活对象的内存达到某个比例时就触发GC。(默认配置会在堆内存达到上一次垃圾收集的2倍时，触发新一轮的垃圾收集，可以通过环境变量GOGC调整，在默认情况下他的值为100，即增长100%的堆内存才会触发GC)；比如一次回收完毕后，内存的使用量为5M，那么下次回收的机制则是内存分配达到10M的时候，也就是说，并不是内存分配越多，垃圾回收频率越高。
2.如果一直达不到内存大小的阙值，sysmon检测出一段时间内（由runtime.forcegcperiod变量控制，默认为2分钟）没有触发过GC，就会触发新的GC。
3.调用runtime.GC()强制触发GC
```

GC调优
**减少堆内存的分配**是最好的优化方式。比如合理重复利用对象；避免string和byte[]之间的转化等，两者发生转换的时候，底层数据结构会进行复制，因此导致gc效率会变低，少量使用+连接string，Go里面string是最基础的类型，是一个只读类型，针对他的每一个操作都会创建一个新的string，如果是少量小文本拼接，用“+”就好，如果是大量小文本拼接，用strings.Join;如果是大量大文本拼接，用bytes.Buffer。

优化努力的方向：

尽可能保持最小的堆内存
最佳的GC频率
保持每次垃圾收集的内存大小
最小化每次垃圾收集的STW和Mark Assist的持续时间

### 3、列举 HTTP状态码 200、400和500分别代表什么?

200    

OK    请求成功。一般用于GET与POST请求

400    

Bad Request    客户端请求的语法错误，服务器无法理解

500    

Internal Server Error    服务器内部错误，无法完成请求

### 4、如何在 Go 中处理 HTTP 超时?

设置超时参数

```
srv := &http.Server{
    ReadTimeout: 5 * time.Second,
    WriteTimeout: 10 * time.Second,
}
```

ReadTimeout指从连接被Accept开始，到request body被完全读取结束（如果读取body的话，否则是读取完header头的时间）。内部是net/http通过在Accept后调用SetReadDeadline实现的。

WriteTimeout一般指从读取完header头之后到写完response的时间（又称ServerHTTP的处理时间），内部通过在 readRequest之后调用SetWriteDeadline实现。

然而，如果是HTTPS的话，SetWriteDeadline方法在Accept后就被调用，所以TLS handshake也是WriteTimeout的一部分。同时，这也意味着（仅仅HTTPS）WriteTimeout包括了读header头以及握手的时间。

为了避免不信任的client端或者网络连接的影响，你应该同时设置这两个值，来保证连接不被client长时间占用。

client端的timeout可以很简单，也可以很复杂，这完全取决于你如何使用。但对于阻止内存泄漏或长时间连接占用的问题上，相对于Server端来说，它同样特别重要。

```
c := &http.Client{
    Timeout: 15 * time.Second,
}
resp, err := c.Get("https://blog.filippo.io/")
```

面提供了很多类型的timeout，可以让你更精细的控制超时：

- net.Dialer.Timeout用于限制建立TCP连接的时间，包括域名解析的时间在内（如果需要创建的话）
- http.Transport.TLSHandshakeTimeout用于限制TLS握手的时间
- http.Transport.ResponseHeaderTimeout用于限制读取响应头的时间（不包括读取response body的时间）
- http.Transport.ExpectContinueTimeout用于限制从客户端在发送包含Expect: 100-continue请求头开始，到接收到响应去继续发送post data的间隔时间。注意：在1.6中 HTTP/2 不支持这个设置(DefaultTransport从1.6.2起是一个例外 1.6.2).

```
c := &http.Client{
    Transport: &http.Transport{
        Dial: (&net.Dialer{
                Timeout:   30 * time.Second,
                KeepAlive: 30 * time.Second,
        }).Dial,
        TLSHandshakeTimeout:   10 * time.Second,
        ResponseHeaderTimeout: 10 * time.Second,
        ExpectContinueTimeout: 1 * time.Second,
    }
}
```

到目前为止，还没有一种方式来限制发送请求的时间。读响应体的时间可以手动的通过设置time.Timer来实现，因为这个过程是在client方法返回之后发生的（后面介绍如何取消一个请求）。

最后，在1.7的版本中增加了http.Transport.IdleConnTimeout，用于限制连接池中空闲连持的存活时间。它不能用于控制阻塞阶段的客户端请求，

注：客户端默认执行请求重定向（302等）。可以为每个请求指定细粒度的超时时间，其中http.Client.Timeout包括了重定向在内的请求花费的全部时间。而http.Transport是一个底层对象，没有跳转的概念。

在1.7的版本中context被引入到了标注库，此处是一些介绍。接下来我们用它来替换 Request.Cancel，实现相同的功能。

使用context来取消一个请求，我们需要获取一个Context类型，以及调用context.WithCancel返回的cancel()方法，并通过Request.WithContext将context绑定到一个请求上。当我们想取消这个请求时，只需要调用cancel()方法

### 5、Gin 框架中如何实现中间件?

Gin的中间件其实就是一个HandlerFunc,那么只要我们自己实现一个HandlerFunc，就可以自定义一个自己的中间件。c.Next方法，这个是执行后续中间件请求处理的意思（含没有执行的中间件和我们定义的GET方法处理）context.Abort()可以提前结束访问

### 6、在Gin中处理panic的最佳实践是什么?

当程序出现panic（即运行时错误）时，程序会立即停止当前的执行流程，并在函数调用堆栈向上逐层返回，直到遇到recover函数或程序终止为止。
而recover函数的作用就是捕获这个panic，并恢复正常的执行流程。在Gin框架中，提供了recover中间件来自动捕获panic，并转换为HTTP 500错误返回给客户端。可以配合日志打印和埋点上报来记录这些错误。以日志打印为例，Gin框架提供了官方的Logger中间件，可以使用Logger来记录错误信息，并在响应中返回了错误提示。这样我们就能及时的发现问题并进行排查了。

### 7、描述 Linux操作系统写入文件的过程。

#### 读流程

1. 应用程序发起读请求，触发系统调用read()函数，用户态切换为内核态；
2. 文件系统通过目录项→inode→address_space→页缓存树，查询Page Cache是否存在；
3. Page Cache不存在产生缺页中断，CPU向DMA发出控制指令；
4. DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的缓冲区（read buffer）；
5. DMA 磁盘控制器向 CPU 发出数据读完的信号，由 CPU 负责将数据从内核缓冲区拷贝到用户缓冲区；
6. 用户进程由内核态切换回用户态，获得文件数据；

![截图](6f2dcb6f98a281b8fd7b9d632e9fe464.png)

时间视角

![截图](06951c50b63790b03eb575749fbf438c.png)

#### 写流程

1. 应用程序发起写请求，触发系统调用write()函数，用户态切换为内核态；
2. 文件系统通过目录项→inode→address_space→页缓存树，查询Page Cache是否存在，如果不存在则需要创建；
3. Page Cache存在后，CPU将数据从用户缓冲区拷贝到内核缓冲区，Page Cache变为脏页（Dirty Page），写流程返回；
4. 用户主动触发刷盘或者达到特定条件内核触发刷盘，唤醒pdflush线程将内核缓冲区的数据刷入磁盘；

![截图](3287a42f77604b66505a131311cb3e4e.png)

#### pdflush回写时机

定时方式执行；

内存不足时；

用户主动触发；

#### DMA传输

  DMA 的全称叫直接内存存取（Direct Memory Access），是一种允许外围设备（硬件子系统）直接访问系统主内存的机制。基于 DMA 访问方式，硬件与内核缓冲区的数据传输由DMA控制器控制，CPU只需在数据传输开始和结束时做一点处理外（开始和结束时候要做中断处理），释放了CPU。目前大多数的硬件设备，包括磁盘控制器、网卡、显卡以及声卡等都支持 DMA 技术。

### 8、描述 Linux操作系统处理多任务的机制

多任务处理是指用户可以在同一时间内运行多个应用程序，每个正在执行的应用程序被称为一个任务。 Linux就是一个支持多任务的操作系统，多任务操作系统使用某种调度策略支持多个任务并发执行。事实上。（单核）处理器在某一时刻只能执行一个任务。每个任务创建时被分配时间片（几十到上百毫秒），任务执行（占用CPU）时，时间片递减，操作系统会在当前任务的时间片用完时调度执行其他任务。由于任务会频繁地切换执行，因此给用户多个任务同时运行的感觉。

#### 任务

任务 是一个逻辑概念，指由一个软件完成的活动，或者是为实现个目的的一系列操作。通常一个任务是一个程序的一次运行，一个任务包含一个或多个完成独立功能的子任务，这个独立的子任务是 进程 或者是 线程。

#### 进程

1. 进程 是指 一个具有独立功能的程序在某个数据集合上的一次动态执行过程。它是操作系统 进行资源分配和调度的基本单元。一次任务的运行可以激活多个进程，这些进程相互合作来完成该任务的一个最终目标。
2. 进程的主要特性
   1. 并发性。指的是系统中多个进程可以同时并发执行，相互之间不受干扰；
   2. 动态性。指的是进程都有完整的生命周期，而且在进程的生命周期内，进程的状态是不断变化的，另外，进程具有动态的地址空间（包括代码、数据和进程控制块等）；
   3. 交互性。指的是进程在执行过程中可能会与其他进程发生直接和间接的通信，如进程同步和进程互斥等，需要为此添加一定的进程处理机制；
   4. 独立性。指的是进程是一个相对完整的资源分配和调度的基本单位，各个进程的地址空间是相互独立的，只有采用某些特定的通信机制才能实现进程之间的通信。
3. Linux 系统中进程的类型
   1. 交互式进程。此类进程经常与用户进行交互，需要等待用户的输入（键盘和鼠标操作等）。当接收到用户的输入之后，这类进程能够立刻响应。
   2. 批处理进程。此类进程不必与用户进行交互，因此通常在后台运行。因为这类进程通常不必很快地响应，因此往往不会优先调度。
   3. 守护进程。这类进程一直在后台运行，和任何终端都不关联。通常系统启动时开始执行，系统关闭时才结束。很多系统进程（各种服务）都是以守护进程的形式存在。
4. Linux下的进程结构
   
   进程 包括程序的指令和数据，也包括程序计数器和处理器的所有寄存器以及存储临时数据的进程堆栈。
  因为Linux是一个多任务的操作系统，所以其他的进程必须等到操作系统将处理器使用权分配给自己之后才能运行。当正在运行的进程需要等待其他的系统资源时，Linux内核将取得处理器的控制权，按照某种调度算法将处理器分配给某个正在等待执行的进程。
  内核将所有的进程存放在双向链表（进程链表）中，链表的每一项都是 task_struct，称为 进程控制块的结构，该结构包含了与一个 进程相关的所有信息，在<include/Linux/sched.h>文件中定义。task_struct 内核结构比较大，它能完整地描述一个进程，如 进程的状态、进程的基本信息、进程标识符、内存相关信息、父进程相关信息、与进程相关的终端信息，当前工作目录，打开的文件信息、所接收的信号信息等。
5. Linux下的进程主要状态
   1. 运行状态（TASK_RUNNING）。进程当前正在运行，或者正在运行队列中等待调度。
   2. 可中断的阻塞状态（TASK_INTERRUPTIBLE）。进程处于阻塞（睡眠）状态，正在等待某些事件发生或能够占用某些共用资源。处在这种状态下的进程可以被信号中断。接收到信号或被显式地唤醒呼叫（如调用 wake_up 系列宏：wake_up、wake_up_interruptible 等）唤醒之后，进程将转变为 TASK_RUNNING 状态。
   3. 不可中断的阻塞状态（TASK_UNINTERRUPTIBLE）。此进程状态类似于可中断的阻塞状态（TASK_INTERRUPTIBLE），只是它不会处理信号，把信号传递到这种状态下的进程不能改变它的状态。在一些特定的情况下（进程必须等待，直到某些不能被中断的事件发生），这种状态是很有用的。只有在它所等待的事件发生时，进程才被显式地唤醒呼叫唤醒。
   4. 暂停状态（TASK_STOPPED）。进程的执行被暂停，当进程收到 SIGSTOP、SIGTSTP、SIGTTIN、SIGTTOU 等信号，就会进入暂停状态。
   5. 僵死状态（EXIT_ZOMBIE）。子进程运行结束，父进程未退出，并且未使用 wait 函数族（比如使用 wait、waitpid 等函数）等系统调用来回收子进程的退出状态。处在该状态下的子进程已经放弃了几乎所有的内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态等信息供其父进程收集。
   6. 消亡状态（EXIT＿DEAD）。这是最终状态，父进程用 wait 函数族回收之后，子进程彻底由系统删除，不可见。
   
   ![截图](482e034e647713ea769f0c15f773729f.png)
   
   Linux 操作系统来用虚拟内存管理技术，使得每个进程都有独立的地址空间。该地址空间是大小为 4GB 的线性虚拟空间，用户所看到和接触到的都是该虚拟地址，无法看到实际的物理内存地址。利用这种虚拟地址不但更安全（用户不能直接访问物理内存），而且用户程序可以使用比实际物理内存更大的地址空间。
   
     4GB 的进程地址空间会被升成两个部分：用户空间 与 内核空间。用户地址空间是 0 - 3GB（0 – 0xC0000000 ），内核地址空间占据 3 - 4GB 的空间位置，用户进程在通常情况下只能访问用户空间的虚拟地址，不能访问内核空间虚拟地址。只有用户进程使用系统调用（代表用户进程在内核态执行）时才可以访问到内核空间。每当进程切换，用户空间就会跟者变化；而内核空间是由内核负责映射，它并不会跟着进程改变，是固定的。内核空间地址有自己对应的页表，用户进程各自有不同的页表。每个进程的用户空间都是完全独立、互不相干的。
![截图](ea8c124a54bcf3021469b0d5ad67d06f.png)

#### 线程

1. 线程概述
  众所周知，进程是系统中程序执行和资源分配的基本单位。每个进程都拥有自己的数据段、代码段和堆栈段，这就造成了进程在进行切换时操作系统的开销比较大。
  所以，为了提高效率， 操作系统又引入了 线程 概念，也称为 轻量级进程。线程可以对进程的内存空间和资源进行访问，并与同一进程中的其他线程共享。因此, 线程的上下文切换的开销比进程小得多。
  另外，一个进程可以拥有多个线程，其中每个线程共享该进程所拥有的资源。要注意的是，由于线程共享了进程的资源和地址空间，因此，任何线程对系统资源的操作都会给其他线程带来影响。所以，多线程中同步是非常关键的问题。

2.  线程标识
  每个线程都包含有表示执行环境所必需的信息，其中包括进程中标识线程的线程ID、一组寄存器、栈、调度优先级和策略、信号屏蔽字、errno标量、线程私有数据等。一个进程的所有信息对该进程的所有线程是共享的，包括可执行程序的代码、程序的全局内存和堆内存、栈、文件描述符。
  线程也有一个线程ID（Linux环境下，线程ID是用无符号长整形来表示的），与进程ID不同的是，线程ID只有在它所属的进程上下文才有意义
  线程可以通过调用函数 pthread_self() 来获取自身的线程ID。
1. 进程和线程的区别
  1、基本区别：进程是资源分配最小单位，线程是程序执行的最小单位；
  2、空间关系：同一进程的各个线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的；
  3、所属关系：线程是进程的一部分，进程中可以包含很多个线程（进程中至少有一个线程，称为主线程），线程也称为轻量级进程；
  4、影响关系：进程相互独立（独立的地址空间），所以一个进程崩溃后，一般不会对其他进程产生影响，但是一个线程（共享地址空间）崩溃整个进程都异常崩溃；
  5、通信关系：同一个进程下，线程共享全局变量，静态变量等数据，所以线程之间的通讯简单，但是存在同步与互斥的难点，进程之间的通信需要以通信的方式（IPC）进行；
  6、开销方面：每个进程都有独立的代码和数据空间（程序上下文），进程之间切换开销大；线程之间共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小；
  7、资源方面：进程对资源保护要求高，开销大，效率相对较低，线程资源保护要求不高，但开销小，效率高，可频繁切换；
  8、 环境关系：在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行；
  9、执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，进程和线程都可以并发执行。
## 二、GRPC(每题4分，合计8分)

### 1、描述GRPC与传统HTTP REST API之间的主要区别

1. REST（Representational State Transfer）表征状态转移，是一种软件架构风格，用于指导WEB架构的设计和开发。REST同样为管理和配置网络设备提供了一种API接口设计的方法。gRPC与REST两者的主要差异如下：
2. REST遵循基于HTTP 1.1的请求-响应通信模型，而gRPC遵循基于HTTP 2.0的客户端-响应通信模型。
HTTP 2.0相对于HTTP 1.1，在速度上有着绝对的优势。虽然REST也可以基于HTTP 2.0进行数据传输，但是为了兼容HTTP 1.1方式，导致其没有充分利用HTTP 2.0的优势。
3. 几乎所有的浏览器都支持REST，而支持gRPC的浏览器非常有限。这是REST相对于gRPC的主要优势。
REST使用JSON或XML编码格式承载数据，而gRPC默认使用ProtoBuf（Protocol Buffers）编码格式承载数据。
ProtoBuf是二进制的，是以二进制数据进行传输，而JSON或XML编码格式以文本形式传输，所以在传输速率上gRPC更具有优势。
4. REST不提供内置代码生成功能，需要使用Swagger等工具生成API请求代码。而gRPC具有protoc编译器，具有代码生成功能，而且protoc编译器与多种编程语言兼容。

![截图](b08c1a994b92fe16f0b9bed7eb19647a.png)

### 2、在GRPC中，什么是拦截器(Interceptor)?

1. 什么是拦截器
gRPC的拦截器（interceptor）类似各种Web框架里的请求中间件，请求中间件大家都知道是利用装饰器模式对最终处理请求的handler程序进行装饰，这样中间件就可以在处理请求前和完成处理后这两个时机上，拦截到发送给 handler 的请求以及 handler 返回给客户端的响应 。
   
   中间件的最大的用处是可以把一些 handler 的前置和后置操作从 handler 程序中解耦出来，比如最常见的记录响应时长、记录请求和响应数据日志等操作往往是通过中间件程序实现的。
   
   与 Web 框架的中间件同理，可以对gRPC的请求和响应进行拦截处理，而且既可以在客户端进行拦截，也可以对服务器端进行拦截。利用拦截器，可以对gRPC进行很好的扩展，把一些业务逻辑外的冗余操作从 handler 中抽离，提升项目的开发效率和扩展性。
2. 与Web框架的中间件不同的是，Web框架可以给每个 handler 程序应用多个中间件，但是gRPC的客户端和服务器分别可以添加一个单向调用类型的拦截器和流式调用类型的拦截器。不过gRPC社区里Go gRPC Middleware 这个软件包提供了拦截器的interceptor链式的功能，可以将多个拦截器组合成一个拦截器链。

## 三、数据库与存储(每题4分，合计8分)

### 1、如何在 Go 中使用 Redis 进行缓存操作?

使用 c, err := redis.Dial("tcp", "192.168.151.158:12004")连接数据库

 使用values, err = c.Do("AUTH", "cqrm123151qaz2WSX")执行函数

对于管道

```
管道：
 c.Send("SET", "name", "red")
 c.Send("GET", "name")
 c.Flush()
 c.Receive()
 c.Receive()
```

### 2、解释 Golang中的ORM，并举例说明如何使用

ORM（Object-Relational Mapping，对象关系映射）框架是一种将面向对象编程语言与关系型数据库之间的映射提供支持的技术。Go语言是一种强大的编程语言，它的标准库提供了对数据库的基本操作，但是在实际应用中，我们往往需要使用ORM框架来简化数据库操作的过程。
GORM是Go语言中一个流行的ORM框架，它提供了丰富的功能和易用性，使得开发者可以更轻松地进行数据库操作。


## 四、综合能力考察(每题6分，合计60分

### 1、什么是 Goroutine 泄漏，如何避免?
runtime.NumGoroutine() 获取当前运行中的 goroutine 数量，通过它确认是否发生泄漏。
#### 什么是 Goroutine 泄露？

当创建一个新的 Goroutine 时，计算机在堆中分配内存，并在执行完成后释放它们。
Goroutine 泄露是一种内存泄露，当 Goroutine 没有终止并在应用程序的生命周期中被留在后台时就会发生。
#### 常见的模式
#### 被遗弃的发送者
遗忘的发送者发生在发送者被阻塞，因为没有接收者在通道的另一侧等待接收数据的情况。
##### 不当使用 Context
```go
func forgottenSender(ch chan int) {
    data := 3
  
    // This is blocked as no one is receiving the data
    ch <- data
}

func handler () {
    ch := make(chan int)
  
    go forgottenSender(ch)
    return
}

```
我们定义了一个上下文，它在10ms后发出超时，随后是一个异步进行网络调用的Goroutine。

select语句等待多个通道操作。它会阻塞，直到其其中一个情况可以运行并执行该情况。

如果网络调用完成之前超时到达，case <- ctx.Done() 将会执行，处理程序将返回一个错误。

当处理程序返回时，不再有任何接收者等待接收数据。forgottenSender将被阻塞，等待有人接收数据，但这永远不会发生！

这就是Goroutine泄露的地方。
##### 错误检查后的接收者位置
```go
func forgottenSender(ch chan int) {
    data := networkCall()
  
    ch <- data
}

func handler() error {
    ch := make(chan int)
    go forgottenSender(ch)
  
    err := continueToValidateOtherData()
    if err != nil {
        return errors.New("Data is invalid! Returning.")
    }
  
    data := <- ch
  
    return nil
}
```
我们定义了一个处理程序并生成一个新的Goroutine来异步进行网络调用。

在等待调用返回的过程中，我们继续其他的验证逻辑。

如你所见，当continueToValidateOtherData返回一个错误导致处理程序返回时，泄露就发生了。

没有人等待接收数据，forgottenSender将永远被阻塞！
#### 解决方案：忘记的发送者

使用一个缓冲通道。

如果你回想一下，忘记的发送者发生是因为另一端没有接收者。阻塞问题的罪魁祸首是一个无缓冲的通道！

一个无缓冲的通道是在消息发出时立即需要一个接收者的，否则发送者会被阻塞。它是在没有为通道分配容量的情况下声明的。
通过为通道添加特定的容量，我们可以减少所有提到的问题。
发送者可以在不需要接收者的情况下将数据注入通道。
#### 被遗弃的接收者

正如其名字所暗示的，被遗弃的接收者是完全相反的情况。
当一个接收者被阻塞，因为另一边没有发送者发送数据时，它就会发生。
```go
func abandonedReceiver(ch chan int) {
    // This will be blocked
    data := <- ch
  
    fmt.Println(data) 
}

func handler() {
    ch := make(chan int)
  
    go abandonedReceiver(ch)
  
    return
}
```
##### 发送者未关闭的通道
```go
func abandonedWorker(ch chan string) {
    for data := range ch {
        processData(data)
    }
  
    fmt.Println("Worker is done, shutting down")
}

func handler(inputData []string) {
    ch := make(chan string, len(inputData))
  
    for _, data := range inputData {
        ch <- data
    }
  
    go abandonedWorker(ch)
    
    return
}
```
处理程序接收一个字符串切片，创建一个通道并将数据插入到通道中。

处理程序然后通过Goroutine启动一个工作程序。工作程序预计会处理数据，并且一旦处理完通道中的所有数据，就会终止。

然而，即使消耗并处理了所有的数据，工作程序也永远不会到达“第6行”！

尽管通道是空的，但它没有被关闭！工作程序继续认为未来可能会有传入的数据。因此，它坐下来并永远等待。

这是Goroutine再次泄漏的地方。
##### 在错误检查之后放置发送者
```go
func abandonedWorker(ch chan []int) {
    data := <- ch

    fmt.Println(data)
}

func handler() error {
    ch := make(chan []int)
    go abandonedWorker(ch)

    records, err := getFromDB()
    if err != nil {
        return errors.New("Database error. Returning")
    }

    ch <- records

    return nil
}
```
处理程序首先启动一个Goroutine工作程序来处理和消费一些数据。

然后，处理程序从数据库中查询记录，然后将记录注入通道供工作程序使用。

如果数据库出现错误，处理程序将立即返回。通道将不再有任何发送者传入数据。

因此，工作程序被遗弃。
#### 解决方案：被遗弃的接收者
在这两种情况下，接收者都被留下，因为他们“认为”通道将有传入的数据。因此，它们阻塞并永远等待。

解决方案是一个简单的单行代码。
```go
defer close(ch)
```
#### nil channel

向 nil channel 发送和接收数据都将会导致阻塞。这种情况可能在我们定义 channel 时忘记初始化的时候发生。
```go
var ch chan int
```
两种写法：<-ch 和 ch<- 1，分别表示接收与发送，都将会导致阻塞。如果想实现阻塞
#### Mutex

和其他语言类似，Go 中存在两种锁，排它锁和共享锁，关于它们的使用就不作介绍了。我们以排它锁为例进行分析。
```go
func main() {
    total := 0

    defer func() {
        time.Sleep(time.Second)
        fmt.Println("total: ", total)
        fmt.Println("the number of goroutines: ", runtime.NumGoroutine())
    }()

    var mutex sync.Mutex
    for i := 0; i < 2; i++ {
        go func() {
            mutex.Lock()
            total += 1
        }()
    }
}
```
这段代码通过启动两个 goroutine 对 total 进行加法操作，为防止出现数据竞争，对计算部分做了加锁保护，但并没有及时的解锁，导致 i = 1 的 goroutine 一直阻塞等待 i = 0 的 goroutine 释放锁。可以看到，退出时有 2 个 goroutine 存在，出现了泄露，total 的值为 1。

怎么解决？因为 Go 有 defer 的存在，这个问题还是非常容易解决的，只要记得在 Lock 的时候，记住 defer Unlock 即可。
#### WaitGroup

WaitGroup 和锁有所差别，它类似 Linux 中的信号量，可以实现一组 goroutine 操作的等待。使用的时候，如果设置了错误的任务数，也可能会导致阻塞，导致泄露发生。
```go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

func handle() {
    var wg sync.WaitGroup

    wg.Add(4)

    go func() {
        fmt.Println("访问表1")
        wg.Done()
    }()

    go func() {
        fmt.Println("访问表2")
        wg.Done()
    }()

    go func() {
        fmt.Println("访问表3")
        wg.Done()
    }()

    wg.Wait()
}

func main() {
    defer func() {
        time.Sleep(time.Second)
        fmt.Println("the number of goroutines: ", runtime.NumGoroutine())
    }()

    go handle()
    time.Sleep(time.Second)
}
```
出现了泄露。再看代码，它的开始部分定义了类型为 sync.WaitGroup 的变量 wg，设置并发任务数为 4，但是从例子中可以看出只有 3 个并发任务。故最后的 wg.Wait() 等待退出条件将永远无法满足，handle 将会一直阻塞。

怎么防止这类情况发生？
建议是，尽量不要一次设置全部任务数，即使数量非常明确的情况。因为在开始多个并发任务之间或许也可能出现被阻断的情况发生。最好是尽量在任务启动时通过 wg.Add(1) 的方式增加。
### 2、Golang 性能调优的一些常用方法是什么?\
[ Go 性能调优之 —— 技巧 - Golang 攻略 - SegmentFault 思否](https://segmentfault.com/a/1190000016354883)
#### 1.1 减少内存分配

Golang的垃圾回收机制对于内存管理非常优秀，但是频繁的内存分配会影响程序的性能。因此，在编写代码时应尽量减少内存分配，可以通过重用变量、使用对象池等方式来实现。

确保你的 APIs 不会给调用方增加垃圾。

考虑这两个 Read 方法
```go
func (r *Reader) Read() ([]byte, error)
func (r *Reader) Read(buf []byte) (int, error)
```
第一个 Read 方法不带参数，并将一些数据作为`[]byte`返回。 第二个采用`[]byte`缓冲区并返回读取的字节数。

第一个 Read 方法总是会分配一个缓冲区，这会给 GC 带来压力。 第二个填充传入的缓冲区。
#### 1.2 使用并发

Golang天生支持并发，可以有效提高程序的性能。在编写代码时应尽量使用并发，可以使用Goroutine和Channel来实现并发。

#### 1.3 减少系统调用

系统调用是操作系统提供的一种接口，用于访问系统资源。由于系统调用涉及到用户态和内核态的切换，因此会影响程序的性能。在编写代码时应尽量减少系统调用，可以通过使用标准库中的函数来实现。

#### 1.4 减少锁竞争

在并发编程中，锁是一种常用的同步机制。但是，锁的使用会导致锁竞争，从而降低程序的性能。在编写代码时应尽量减少锁竞争，可以通过使用无锁数据结构、粒度更细的锁等方式来实现。

#### 1.5 使用缓存

缓存是一种常用的优化手段，可以有效减少系统开销。在编写代码时应尽量使用缓存，可以使用缓存库来实现。
#### 1.6 基准测试
#### 1.7 逃逸分析逃逸分析
#### 内联

在 Go 中，函数调用有固定的开销；栈和抢占检查。

硬件分支预测器改善了其中的一些功能，但就功能大小和时钟周期而言，这仍然是一个成本。

内联是避免这些成本的经典优化方法。

内联只对叶子函数有效，叶子函数是不调用其他函数的。这样做的理由是:

- 如果你的函数做了很多工作，那么前序开销可以忽略不计。
- 另一方面，小函数为相对较少的有用工作付出固定的开销。这些是内联目标的功能，因为它们最受益。

还有一个原因就是严重的内联会使得堆栈信息更加难以跟踪。
##### 分支消除
是一种被称为死码消除的优化。实际上，使用静态证明来表明一段代码永远不可达，通常称为死代码，因此它不需要在最终的二进制文件中编译、优化或发出。

我们发现死码消除与内联一起工作，以减少循环和分支产生的代码数量，这些循环和分支被证明是不可到达的。

你可以利用这一点来实现昂贵的调试，并将其隐藏起来
#### 1.8性能测量和分析

在先前的部分，我们研究了对单个函数的基准测试，当您提前知道瓶颈在哪里时，这是非常有用的。然而，你经常会发现自己处于提问的位置

> 为什么这个程序要运行这么长时间？

剖析整个程序，这对于回答诸如此类的高级问题非常有用。在本节中，我们将使用Go内置的分析工具从内部研究程序的操作。
### 3、解释 Golang中的反射(reflection)以及其使用场景。
**反射机制**主要用于在运行时检查变量的类型和值、调用变量的方法以及动态操作对象。反射机制在Go中通过`reflect`包实现，它允许程序操作任意类型的对象。**反射最常见的用途包括：类型检查、动态调用方法、以及结构体标签的处理**。其中，动态调用方法是反射的一个核心应用，它允许开发者在运行时调用一个对象的方法，即使这个方法在编译时并不确定。
#### 一、反射的基本概念

反射在Go语言中是通过`reflect`包提供的功能来实现的。要使用反射，首先需要理解两个基本概念：`Type`和`Value`。`Type`代表了Go语言中的一个类型，而`Value`则代表了具体的值。

##### 类型和值

通过`reflect.TypeOf()`和`reflect.ValueOf()`函数，我们可以获取任意对象的类型和值。这是反射最基础也是最重要的功能。了解了一个变量的`Type`和`Value`，我们就能进一步探索其内部结构，包括它的字段、方法等。

##### 动态调用方法

反射的一个重要应用是能够动态地调用方法。这意味着，我们可以在运行时根据条件选择调用对象的不同方法，而不是在编译时固定选择。这为编写通用代码和库提供了极大的灵活性和动态性。

#### 二、如何使用反射

使用反射需要导入`reflect`包。以下是一些基本的使用方法：

##### 检查类型和值

首先，我们可以使用`reflect.TypeOf()`和`reflect.ValueOf()`来检查任意变量的类型和值。这是学习反射的起点。

##### 获取结构体信息

反射还可以用来获取结构体的信息，比如字段名、类型以及标签。这对于处理JSON或XML等格式的数据非常有用，因为你可以动态地读取数据结构，而无需事先知道其结构。

##### 调用方法

通过反射，我们还可以动态地调用对象的方法，即使这个方法在编译时并不是已知的。这通过`reflect.Value`的`MethodByName()`方法实现。这种能力特别适用于设计框架或库，其中某些行为需要在运行时确定。

#### 三、反射的使用场景

##### 动态配置和解析

在配置系统或解析复杂数据结构时，反射可以动态地处理不同类型的数据，而不需要编写大量的类型断言和类型转换代码。

##### 通用编程

反射使得编写通用函数成为可能，这些函数可以处理各种类型的数据。例如，一个基于反射的打印函数可以接受任何类型的参数，并且智能地打印其内容。

##### 框架开发

在开发框架时，反射是不可或缺的工具。它允许框架开发者提供灵活且强大的API，用户可以用极少的代码就实现复杂的功能。例如，许多Web框架使用反射来处理路由和请求绑定。

#### 四、反射的注意事项

尽管反射提供了强大的功能，但它也有一定的性能开销。反射操作通常比直接的类型断言和方法调用慢。因此，在性能敏感的应用中应谨慎使用。

此外，过度依赖反射可能会使代码难以理解
### 4、描述 Go 程序中死锁的概念，并提供一个简单的示例,
#### 什么是死锁？

死锁是指两个或更多的进程永久性地互相等待对方释放资源的情况。这通常发生在每个进程都持有至少一个资源，但又需要另一个当前被其他进程持有的资源才能继续执行。
```go
package main 
func main() { 
	ch1 := make(chan int) 
	ch2 := make(chan int) 
	go func() {
	 <-ch1 ch2 <- 1 
	 }() 
	go func() { <-ch2 ch1 <- 1 
	}() 
	select {} }
```
#### 如何避免死锁？

避免死锁的关键在于设计和管理好程序中的并发逻辑。以下是一些避免死锁的策略：

- **避免无限制的等待：** 设计程序以避免goroutine永久等待某些事件。可以使用带有超时的通道操作，或者使用 `context` 包来设置超时和取消操作。
- **使用buffered channel：** buffered channel允许发送方在没有接收方准备好的情况下仍然能发送数据，这可以在某些情况下避免死锁。
- **使用锁的顺序**： 如果我们的程序使用了多个锁，确保所有的goroutine都按照相同的顺序获取和释放锁，这可以避免死锁。
### 5、解释Keepalived在 Linux系统中的故障切换原理。
#### Keepalived是什么？  
keepalived软件起初是专门为LVS负载均衡软件而设计，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用的VRRP功能，因此，keepalived除了能够管理LVS软件ipvsadm外，还可以作为其它服务（例如：Nginx、HAProxy、MySQL等）的高可用解决方案软件 keepalived软件主要使用过VRRP协议实心高可用功能；VRRP是Virtual Route Redundancy Protocol（虚拟路由冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行 所以，Keepalived一方面具有配置管理LVS的功能，同时还具有LVS下面节点进行健康检查的功能，另一方面也可以实现系统网络服务的高可用功能
#### Keepalived服务的三个重要功能
1）管理LVS负载均衡软件ipvsadm 
2）实现LVS集群节点的健康检查 
3）作为系统网络服务的高可用性

#### Keepalived高可用故障切换转移原理 
Keepalived高可用服务之间的故障切换转移，还是通过VRRP（Vritual Route Redundancy Protocol，虚拟路由冗余协议）来实现的 在Keepalived服务正常工作时，主Master节点会不断向备节点发送心跳消息（多播的方式），用来告诉备用节点自己还活着，当主Master节点发送故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主Master的心跳消息了，于是调用自身的接管程序，接管主Master节点的IP资源及服务。而当主Master恢复时，备Backup节点默认又会主动释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。
![[Pasted image 20240303165239.png]]
### 6、阐述LVS(Linux Virtual Server)的工作原理和架构
LVS是Linux virtual server的缩写，为linux虚拟服务器，是一个虚拟的服务器集群系统。LVS简单工作原理为用户请求LVS VIP，LVS根据转发方式和算法，将请求转发给后端服务器，后端服务器接收到请求，返回给用户。对于用户来说，看不到Web后端具体的应用。
#### 一、LVS负载均衡简介
可伸缩网络服务有很多结构，但都有一个共同点：它们都需要一个前端的负载调度器。而实现虚拟网络服务的主要技术指出IP负载均衡技术是在负载调度器的实现技术里面效率最高的一个。
在已有的IP负载均衡技术中，主要有通过网络地址转换将一组服务器构成一个高性能的、高可用的虚拟服务器，通常称为VS/NAT技术。在分析VS/NAT的缺点和网络服务的非对称的基础上，可以通过IP隧道实现虚拟服务器的方法VS/TUN和通过直接路由实现虚拟服务器的方法VS/DR，它们可以极大地提高系统的伸缩性。(摘自 LINUX企业运维实战一书中)

#### 二、LVS结构
LVS集群分为三层结构：
1. 负载调度器(Load Blancer):是整个LVS集群对外的前端机器，负责敬爱嗯client的请求发送到一组服务器【多台 LB IP】上执行，而client则认为返回来是同一个IP(通常把这个IP成为虚拟ip或VIP)
2. 服务器池(server pool):一组真正执行clinet请求的服务器，一般是web服务器；除了web，还有FTP、MAIL、DNS等
3. 共享存储(shared stord):它为server pool提供了一个共享的存储区，很容易让服务器池拥有相同的内容，提供相同的服务
#### 三、LVS相关术语
* DS：Director Server。指的是前端负载均衡器节点
* RS：Real Server。后端真实的工作服务器
* VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址
* DIP：Director Server IP，主要用于和内部主机通讯的IP地址
* RIP：Real Server IP，后端服务器的IP地址
* CIP：Client IP，访问客户端的IP地址
#### 四、LVS负载均衡工作原理
##### 1、LVS DR模式
LVS DR原理详解图
![[Pasted image 20240303165738.png]]LVS DR原理：用户请求LVS到达director，director将请求的报文的目的MAC地址改为后端的realserver的MAC地址，目的IP为VIP(不变)，源IP为client IP地址(不变)，然后director将报文发送到realserver，realserver检测到目的地址为自己本地的VIP，如果在同一网段，将请求直接返回给用户，如果用户跟realserver不在同一个网段，则需要通过网关返回给用户。

LVS DR特性：

前端路由将目标地址为VIP报文统统发给Director Server
RS跟Director Server必须有一个网卡在同一个物理网络中
所有的请求报文经由Director Server，但响应报文必须不能进过Director Server
所有的real server机器上都有VIP地址
##### 2、LVS NAT模式
LVS NAT原理详解图
![[Pasted image 20240303165805.png]]LVS NAT原理：用户请求LVS到达director，director将请求的报文的目的IP改为RIP，同时将报文的目标端口也改为realserver的相应端口，最后将报文发送到realserver上，realserver将数据返回给director，director再把数据发送给用户

LVS NAT特性：

NAT模式修改的是目的ip，直接走的是switch不需要修改mac地址，所以VIP和RIP不需要在同一个网段内
NAT的包的进出都需要经过LVS，所以LVS可能会成为一个系统的瓶颈问题
##### 3、LVS FULLNAT模式
LVS FULLNAT报文变化
![[Pasted image 20240303165846.png]]
**LVS FULLNAT特性：**

- FULLNAT模式也不需要DIP和RIP在同一网段
- FULLNAT和NAT相比的话：会保证RS的回包一定可到达LVS
- FULLNAT需要更新源IP，所以性能正常比NAT模式下降10%
![[Pasted image 20240303165914.png]]

##### 4、LVS TUN原理
LVS TUN原理：用户请求LVS到达director，director通过IP-TUN加密技术将请求报文的包封装到一个新的IP包里面，目的IP为VIP(不变)，然后director将报文发送到realserver，realserver基于IP-TUN解密，然后解析出来包的目的为VIP，检测网卡是否绑定了VIP，绑定了就处理这个包，如果在同一个网段，将请求直接返回给用户，否则通过网关返回给用户；如果没有绑定VIP就直接丢掉这个包
**LVS TUN原理详解图**![[Pasted image 20240303170021.png]]
LVS TUN特性：

TUNNEL必须在所有的realserver上绑定VIP
realserver直接把包发给client
隧道模式运维起来会比较难，所以一般不用
#### 四种模式的比较
1. 是否需要VIP和realserver在同一网段
DR模式因为只修改包的MAC地址，需要通过ARP广播找到realserver，所以VIP和realserver必须在同一个网段，也就是说DR模式需要先确认这个IP是否只能挂在这个LVS下面；其他模式因为都会修改目的地址为realserver的IP地址，所以不需要在同一个网段内
2. 是否需要在realserver上绑定VIP
realserver在收到包之后会判断目的地址是否是自己的IP
DR模式的目的地址没有修改，还是VIP，所以需要在realserver上绑定VIP
IP TUN模式值是对包重新包装了一层，realserver解析后的包的IP仍然是VIP，所以也需要在realserver上绑定VIP
3. 四种模式的性能比较
DR模式、IP TUN模式都是在包进入的时候经过LVS，在包返回的时候直接返回给client；所以二者的性能比NAT高
但TUN模式更加复杂，所以性能不如DR
FULLNAT模式不仅更换目的IP还更换了源IP，所以性能比NAT下降10%
性能比较：DR>TUN>NAT>FULLNAT
#### LVS负载均衡十种算法
1. 轮叫调度 rr
2. 
均等地对待每一台服务器，不管服务器上的实际连接数和系统负载

2. 加权轮叫 wrr
调度器可以自动问询真实服务器的负载情况，并动态调整权值

3. 最少链接 lc
动态地将网络请求调度到已建立的连接数最少的服务器上
如果集群真实的服务器具有相近的系统性能，采用该算法可以较好的实现负载均衡

4. 加权最少链接 wlc
调度器可以自动问询真实服务器的负载情况，并动态调整权值
带权重的谁不干活就给谁分配，机器配置好的权重高

5. 基于局部性的最少连接调度算法 lblc
这个算法是请求数据包的目标 IP 地址的一种调度算法，该算法先根据请求的目标 IP 地址寻找最近的该目标 IP 地址所有使用的服务器，如果这台服务器依然可用，并且有能力处理该请求，调度器会尽量选择相同的服务器，否则会继续选择其它可行的服务器

6. 复杂的基于局部性最少的连接算法 lblcr
记录的不是要给目标 IP 与一台服务器之间的连接记录，它会维护一个目标 IP 到一组服务器之间的映射关系，防止单点服务器负载过高。

7. 目标地址散列调度算法 dh
该算法是根据目标 IP 地址通过散列函数将目标 IP 与服务器建立映射关系，出现服务器不可用或负载过高的情况下，发往该目标 IP 的请求会固定发给该服务器。

8. 源地址散列调度算法 sh
与目标地址散列调度算法类似，但它是根据源地址散列算法进行静态分配固定的服务器资源。

9. 最少期望延迟 sed
不考虑非活动链接，谁的权重大，优先选择权重大的服务器来接收请求，但权重大的机器会比较忙

10. 永不排队 nq
无需队列，如果有realserver的连接数为0就直接分配过去

### 7、描述 NSQ消息队列系统中消息的写入和读取过程。
#### NSQ组件

NSQ 由 3 个守护进程组成:

- **_nsqd_** 是接收、队列和传送消息到客户端的守护进程。
- **_nsqlookupd_** 是管理的拓扑信息，并提供了最终一致发现服务的守护进程。
- **_nsqadmin_** 是一个 Web UI 来实时监控集群(和执行各种管理任务)。
#### NSQ架构
![[Pasted image 20240303193413.png]]
##### topic消息的逻辑关键词

- **topic** 是 **NSQ** 消息发布的 **逻辑关键词** ，可以理解为人为定义的一种消息类型。当程序初次发布带 **topic** 的消息时,如果 **topic** 不存在,则会在 **_nsqd_**中创建。

##### producer消息的生产者/发布者

- **producer** 通过 **HTTP API** 将消息发布到 **nsqd** 的指定 **topic** ，一般有 **pub/mpub** 两种方式， **pub** 发布一个消息， **mpub** 一个往返发布多个消息。
- **producer** 也可以通过 **nsqd客户端** 的 **TCP接口** 将消息发布给 **nsqd** 的指定 **topic** 。
- 当生产者 **producer** 初次发布带 **topic** 的消息给 **nsqd** 时,如果 **topic** 不存在，则会在 **nsqd** 中创建 **topic** 。

##### channel消息传递的通道

- 当生产者每次发布消息的时候,消息会采用多播的方式被拷贝到各个 **_channel_** 中, **_channel_** 起到队列的作用。
- **_channel_** 与 **_consumer(消费者)_** 相关，是消费者之间的负载均衡,消费者通过这个特殊的channel读取消息。
- 在 **_consumer_** 想单独获取某个 **topic** 的消息时，可以 **_subscribe(订阅)_**一个自己单独命名的 **_nsqd_**中还不存在的 **_channel_**, **_nsqd_**会为这个 **_consumer_**创建其命名的 **_channel_**
- **_Channel_** 会将消息进行排列，如果没有 **_consumer_**读取消息，消息首先会在内存中排队，当量太大时就会被保存到磁盘中。可以在配置中配置具体参数。
- 一个 **_channel_** 一般会有多个 **_consumer_** 连接。假设所有已连接的 **_consumer_** 处于准备接收消息的状态，每个消息将被传递到一个随机的 **_consumer_**。
- Go语言中的channel是表达队列的一种自然方式，因此一个NSQ的topic/channel，其核心就是一个存放消息指针的Go-channel缓冲区。缓冲区的大小由 --mem-queue-size 配置参数确定。

##### consumer消息的消费者

- **_consumer_** 通过 **TCP** **_subscribe_** 自己需要的 **_channel_**  
    **_topic_** 和 **_channel_** 都没有预先配置。 **_topic_** 由第一次发布消息到命名 **_topic_** 的 **_producer_** 创建 **_或_** 第一次通过 **_subscribe_** 订阅一个命名 **_topic_** 的 **_consumer_** 来创建。 **_channel_** 被 **_consumer_** 第一次 **_subscribe_** 订阅到指定的 **_channel_** 创建。
- 多个 **_consumer_** **_subscribe_**一个 **_channel_**，假设所有已连接的客户端处于准备接收消息的状态，每个消息将被传递到一个 **随机** 的 **_consumer_**。
- NSQ 支持延时消息， **_consumer_** 在配置的延时时间后才能接受相关消息。
- Channel在 **_consumer_** 退出后并不会删除，这点需要特别注意。
#### 概述

- NSQ推荐通过 **_nsqd_** 实例使用协同定位 **_producer_**，这意味着即使面对网络分区，消息也会被保存在本地，直到它们被一个 **_consumer_**读取。更重要的是， **_producer_**不必去发现其他的 **_nsqd_**节点，他们总是可以向本地 **_nsqd_**实例发布消息。  
      
    
- 一个 **_producer_**向它的本地 **_nsqd_**发送消息，要做到这点，首先要先打开一个连接( NSQ 提供 **_HTTP API_** 和 **_TCP 客户端_** 等2种方式连接到 **_nsqd_**)，然后发送一个包含 **_topic_**和消息主体的发布命令(pub/mpub/publish)，在这种情况下，我们将消息发布到 **_topic_**上，消息会采用多播的方式被拷贝到各个 **_channel_**中, 然后通过多个 **_channel_**以分散到我们不同需求的 **_consumer_**中。
#### NSQD
##### nsqd基本结构
![[Pasted image 20240303193638.png]]
利用svc框架来启动服务, Run 时, 先后调用svc框架的 Init 和 Start 方法 ，然后开始不断监听退出的信号量, 最后调用 svc框架的Stop 方法来退出。  
  
svc框架的Start方法从本地文件读取数据初始化topic和channel，然后调用功能入口Main方法。Main方法利用waitGroup框架来启动4个服务线程，至此启动完毕。  
  
WaitGroup来自sync包，用于线程同步，单从字面意思理解，wait等待的意思，group组、团队的意思，WaitGroup就是等待一组服务执行完成后才会继续向下执行，涉及到WG个数的操作都使用原子操作来保证线程安全。
##### nsqd详细流程图
![[Pasted image 20240303193753.png]]
#### NSQ使用

> 首先启动 **_nsdlookupd_**

```bash
nsqlookupd
```

- 客户端通过查询 **_nsdlookupd_** 来发现指定topic的生产者，并且 **_nsqd_** 节点广播 **_topic_** 和通道 **_channel_** 信息
- 该服务运行后有两个端口：TCP 接口，**_nsqd_** 用它来广播；HTTP 接口，客户端用它来发现和管理。
- 在生产环境中，为了高可用，最好部署三个nsqlookupd服务。

> 先创建 **_nsqd_** 的数据路径

```bash
mkdir /tmp/nsqdata1 /tmp/nsqdata2
```


> 运行两个测试的 **_nsqd_** 实例

```text
nsqd --lookupd-tcp-address=127.0.0.1:4160 -broadcast-address=127.0.0.1 -tcp-address=127.0.0.1:4150 -http-address=0.0.0.0:4151 -data-path=/tmp/nsqdata1

nsqd --lookupd-tcp-address=127.0.0.1:4160 -broadcast-address=127.0.0.1 -tcp-address=127.0.0.1:4152 -http-address=0.0.0.0:4153 -data-path=/tmp/nsqdata2
```

- **_nsqd_** 可以独立运行，不过通常它是由 **_nsdlookupd_** 实例所在集群配置的(它在这能声明 **_topics_** 和 **_channels_** ，以便大家能找到)
- 服务启动后有两个端口：一个给客户端(TCP)，另一个是 HTTP API。还能够开启HTTPS。
- 同一台服务器启动多个 **_nsqd_** ，要注意端口和数据路径必须不同，包括： **_–lookupd-tcp-address_** 、 **_-tcp-address_** 、 **_–data-path_**
- 删除 **_topic_** 、**_channel_** 需要 **_HTTP API_** 调用。

  

> 启动 **_nsqadmin_** 前端Web监控

```text
nsqadmin --lookupd-http-address=localhost:4161
```

- **_nsqadmin_** 是一套 **_WEB UI_** ，用来汇集集群的实时统计，并执行不同的管理任务。
- 运行后，能够通过4171端口查看并管理 **_topic_** 和 **_channel_** 。
- **_nsqadmin_** 通常只需要运行一个。
#### 测试1
- 2个Producer 1个Consumer
- produce1() 发布publish "x","y" 到 topic "test"
- produce2() 发布publish "z" 到 topic "test"
- consumer1() 订阅subscribe channel "sensor01" of topic "test"

```go
package test

import (
        "log"
        "time"
        "testing"
        "strconv"

        "github.com/nsqio/go-nsq"
)

func TestNSQ1(t *testing.T) {
       NSQDsAddrs := []string{"127.0.0.1:4150", "127.0.0.1:4152"}
       go consumer1(NSQDsAddrs)
       go produce1()
       go produce2()
       time.Sleep(30 * time.Second)
}

func produce1() {
        cfg := nsq.NewConfig()
        nsqdAddr := "127.0.0.1:4150"
        producer, err := nsq.NewProducer(nsqdAddr, cfg)
        if err != nil {
                log.Fatal(err)
        }
        if err := producer.Publish("test", []byte("x")); err != nil {
                log.Fatal("publish error: " + err.Error())
        }
        if err := producer.Publish("test", []byte("y")); err != nil {
                log.Fatal("publish error: " + err.Error())
        }
}

func produce2() {
        cfg := nsq.NewConfig()
        nsqdAddr := "127.0.0.1:4152"
        producer, err := nsq.NewProducer(nsqdAddr, cfg)
        if err != nil {
                log.Fatal(err)
        }
        if err := producer.Publish("test", []byte("z")); err != nil {
                log.Fatal("publish error: " + err.Error())
        }
}

func consumer1(NSQDsAddrs []string) {
        cfg := nsq.NewConfig()
        consumer, err := nsq.NewConsumer("test", "sensor01", cfg)
        if err != nil {
                log.Fatal(err)
        }
        consumer.AddHandler(nsq.HandlerFunc(
                func(message *nsq.Message) error {
                        log.Println(string(message.Body) + " C1")
                        return nil
                }))
        if err := consumer.ConnectToNSQDs(NSQDsAddrs); err != nil {
                log.Fatal(err, " C1")
        }
        <-consumer.StopChan
}
```
### 8、描述 Kubernetes中自定义资源定义(CRD)的概念及其用途。
#### 什么是自定义资源定义（CRD）？

CRD 是 Kubernetes 中的一种扩展机制，允许用户定义自己的资源类型。通常情况下，Kubernetes 提供了一系列内建的资源类型，如 Pod、Service、Deployment 等。然而，这些内建资源并不能满足所有业务需求，因此引入了 CRD，使得用户可以定义和使用自己的资源类型。

通过定义 CRD，用户可以将自己的应用程序或服务的业务逻辑抽象为 Kubernetes 中的一种资源类型，从而更方便、更一致地进行管理和编排。

#### CRD 对于 Kubernetes 的意义

CRD 为 Kubernetes 提供了以下重要的优势和意义：

##### 1. 定制资源类型

CRD 允许用户在 Kubernetes 中定义自己的资源类型，这些资源类型可以完全适应用户的应用程序或服务的需求。这种灵活性使得 Kubernetes 能够更好地支持各种不同类型的工作负载。

##### 2. 统一管理

CRD 将自定义资源纳入 Kubernetes 统一的管理体系中，使得用户可以使用相同的工具和流程来管理自定义资源和内建资源。这种一致性有助于简化管理工作，降低学习成本。

##### 3. 更好的扩展性

通过引入 CRD，Kubernetes 的架构变得更加灵活和可扩展。用户可以根据自己的需求，轻松扩展 Kubernetes 的能力，而无需修改 Kubernetes 的核心代码。

##### 4. 与生态系统集成

CRD 使得用户可以更好地将自己的应用程序或服务整合到 Kubernetes 生态系统中。例如，使用 Helm 等工具，可以轻松地部署和管理包含 CRD 的应用程序。

#### 如何使用 CRD
为了使用 CRD，首先需要定义一个 CRD 的规范，然后将其注册到 Kubernetes 集群中。以下是一个简单的示例，演示如何定义一个名为 `Example` 的 CRD：

```text
# example-crd.yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: examples.example.com
spec:
  group: example.com
  versions:
    - name: v1
      served: true
      storage: true
  scope: Namespaced
  names:
    plural: examples
    singular: example
    kind: Example
    shortNames:
    - ex
```

  

在上述示例中，我们定义了一个名为 `Example` 的 CRD，其 API Group 为 `example.com`，版本为 `v1`。该 CRD 允许在命名空间中使用，并定义了资源名称的复数和单数形式，以及资源的简称。

接下来，我们可以使用 `kubectl apply` 命令将这个 CRD 注册到 Kubernetes 集群中：

```text
kubectl apply -f example-crd.yaml
```
现在，我们可以创建一个 `Example` 资源实例：

```text
# example-instance.yaml
apiVersion: example.com/v1
kind: Example
metadata:
  name: example-instance
spec:
  foo: "bar"
```

使用 `kubectl apply` 命令将这个资源实例创建到 Kubernetes 集群中：

```text
kubectl apply -f example-instance.yaml
```
通过以下命令，我们可以查看 `Example` 资源的详细信息：

```text
kubectl get example example-instance -o yaml
```

  

这样，我们就成功地使用了一个简单的 CRD，并创建了一个相应的资源实例。

#### CRD 的规范详解

上面的示例中，我们已经简要介绍了一个 CRD 的定义，下面我们将详细解释一个 CRD 的各个部分。

##### 1. `apiVersion` 和 `kind`

```text
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
```

  

这两个字段指定了 YAML 文件的 API 版本和资源类型。在定义 CRD 时，通常都使用 `apiextensions.k8s.io/v1` 版本的 `CustomResourceDefinition` 类型。

##### 2. `metadata.name`

```text
metadata:
  name: examples.example.com
```

  

`metadata.name` 字段定义了 CRD 的名称。这个名称应该是唯一的，并且符合 DNS 子域名的命名规范。

##### 3. `spec.group` 和 `spec.versions`

```text
spec:
  group: example.com
  versions:
    - name: v1
      served: true
      storage: true
```

  

`spec.group` 定义了 CRD 的 API 组。`spec.versions` 字段定义了支持的 API 版本。每个版本包含 `name`（版本名称）、`served`（是否提供服务，即是否可以创建资源实例）和 `storage`（是否进行持久化存储）等属性。

##### 4. `spec.scope`

```text
spec:
  scope: Namespaced
```

  

`spec.scope` 字段定义了资源的作用域。可以是 `Cluster`（全局作用域）或 `Namespaced`（命名空间作用域）。

##### 5. `spec.names`

```text
spec:
  names:
    plural: examples
    singular: example
    kind: Example
    shortNames:
    - ex
```

  

`spec.names` 字段定义了 CRD 中资源名称的一些属性。其中包括 `plural`（资源名称的复数形式）、`singular`（资源名称的单数形式）、`kind`（资源的 Kubernetes 类型）和 `shortNames`（资源的简称）。

#### 结语
自定义资源定义（CRD）是 Kubernetes 中非常强大的一项特性，它为用户提供了定义和使用自定义资源类型的能力。通过 CRD，用户可以更灵活地扩展 Kubernetes，适应各种不同类型的工作负载。CRD 的设计和使用需要谨慎，但在合适的场景下，它将是 Kubernetes 中实现自定义需求的理想选择。希望本文对你理解和使用 Kubernetes 中的 CRD 提供了有益的指导。
### 9、概述etcd的主要功能和在分布式系统中的作用。
etcd（读作 et-see-dee）是一种开源的分布式统一键值存储，用于分布式系统或计算机集群的共享配置、服务发现和的调度协调。etcd 有助于促进更加安全的自动更新，协调向主机调度的工作，并帮助设置容器的覆盖网络。

etcd 是许多其他项目的核心组件。最值得注意的是，它是 Kubernetes的首要数据存储，也是容器编排的实际标准系统。使用 etcd， 云原生应用可以保持更为一致的运行时间，而且在个别服务器发生故障时也能正常工作。应用从 etcd 读取数据并写入到其中；通过分散配置数据，为节点配置提供冗余和弹性。
#### 什么是 etcd Operator？

通过使用 Operator（代表人类运维知识 ），使得 etcd 更容易在 Kubernetes 或 Kubernetes 容器平台上使用。etcd Operator 在 Operator 框架内管理 etcd，并用于简化 etcd 集群配置和管理。  
  
etcd Operator 可通过一个简单的命令来安装，也允许用户使用简单的声明式配置来创建、配置和管理 etcd 集群，从而配置和管理 etcd 的复杂设置。  

etcd Operator 提供以下功能：

- **创建/部署** - 用户只需要指定集群大小，不必逐一为 etcd 成员指定繁杂的配置设置。
    
- **调整大小** - 用户只需要在规格中指定大小，etcd Operator 便会负责部署、销毁和/或重新配置集群成员。
    
- **备份** - etcd Operator 可以自动、透明地执行备份。用户只需要指定备份策略即可。例如，_每隔 30 分钟备份一次，并保留最近的 3 个备份。_
    
- **升级** - 在不停机的情况下升级 etcd 是一项重要但又棘手的任务。通过 etcd Operator 执行升级，可以简化运维工作并避免常见的升级错误。
#### etcd 的作用是什么？

etcd Operator 通过 3 个步骤来模拟人类运维人员的行为：观察、分析和操作。

1. Operator 通过使用 Kubernetes API 来观察当前的集群状态。
    
2. 然后，查明预期状态和当前状态之间的差异。
    
3. 最后，通过利用 etcd 集群管理 API 和/或 Kubernetes API 缩小这些差异。

### 10、解释 EnvoyXDS协议以及其下不同数据平面(DS)的概念和作用
xDS 协议是“X Discovery Service”的简写，这里的“X”表示它不是指具体的某个协议，是一组基于不同数据源的服务发现协议的总称，包括 CDS、LDS、EDS、RDS等。在Istio架构中，基于xDS协议提供了标准的控制面规范，并以此向数据面传递服务信息和治理规则。在Envoy中，xDS被称为数据平面 API，并且担任控制平面Pilot和数据平面Envoy的通信协议。

CDS 是 Cluster Discovery Service的缩写，Envoy使用它在进行路由的时候发现上游Cluster。Envoy通常会优雅地添加、更新和删除 Cluster。有了 CDS 协议，Envoy在初次启动的时候不一定要感知拓扑里所有的上游Cluster。在做路由 HTTP 请求的时候通过在 HTTP 请求头里添加 Cluster信息实现请求转发。

EDS 即Endpoint Discovery Service 的缩写。在Envoy术语中，Endpoint即Cluster的成员。Envoy 通过 EDS API可以更加智能地动态获取上游Endpoint。

LDS 即Listener Discovery Service的缩写。基于此，Envoy 可以在运行时发现所有的Listener，包括 L3 和 L4 filter 等所有的 filter 栈，并由此执行各种代理工作，如认证、TCP 代理和 HTTP 代理等。添加 LDS 使得 Envoy 的任何配置都可以动态执行。

RDS 即 Router Discovery Service 的缩写，用于 Envoy 在运行时为 HTTP 连接管理 filter 获取完整的路由配置，比如 HTTP 头部修改等。并且路由配置会被优雅地写入而无需影响已有的请求。当 RDS 和 EDS、CDS 共同使用时，可以帮助构建一个复杂的路由拓扑蓝绿发布等。

ADS EDS，CDS 等每个独立的服务都对应了不同的 gRPC 服务名称。对于需要控制不同类型资源抵达 Envoy 顺序的需求，可以使用聚合发现服务，即 Aggregated xDS，它可以通过单一的 gRPC 服务流支持所有的资源类型，借助于有序的配置分发，从而解决资源更新顺序的问题。
#### 数据平面介绍

数据平面由一组以 sidecar 方式部署的智能代理组成。 这些代理可以调节和控制微服务之间所有的网络通信。 数据平面真正触及到对网络数据包的相关操作，是上层控制平面策略的具体执行者。

在服务网格中，数据平面 sidecar 代理主要负责执行如下任务：

- 服务发现：探测所有可用的上游或后端服务实例
- 健康检测：探测上游或后端服务实例是否健康，是否准备好接收网络流量
- 流量路由：将网络请求路由到正确的上游或后端服务
- 负载均衡：在对上游或后端服务进行请求时，选择合适的服务实例接收请求，同时负责处理超时、断路、重试等情况
- 身份验证和授权：对网络请求进行身份验证、权限验证，以决定是否响应以及如何响应，使用 mTLS 或其他机制对链路进行加密等
- 链路追踪：对于每个请求，生成详细的统计信息、日志记录和分布式追踪数据，以便操作人员能够理解调用路径并在出现问题时进行调试

简单来说，数据平面就是负责有条件地转换、转发以及观察进出服务实例的每个网络包。

典型的数据平面实现有：[Linkerd](https://linkerd.io/)、[NGINX](https://www.nginx.com/)、[HAProxy](https://www.haproxy.com/)、[Envoy](https://envoyproxy.github.io/)、[Traefik](https://traefik.io/)